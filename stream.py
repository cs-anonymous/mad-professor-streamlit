import streamlit as st
from util.data_manager import DataManager
# Add at the very top before other imports
import os
import json  # æ·»åŠ åœ¨æ–‡ä»¶é¡¶éƒ¨
from util.AI_professor_chat import AIProfessorChat
import uuid
import shutil
import re
import urllib.parse  # æ·»åŠ å¯¼å…¥
from pypinyin import lazy_pinyin


os.environ["TORCH_DISABLE_MLOCK"] = "1"  # Disable PyTorch memory locking

# åº”ç”¨åŸºç¡€é…ç½®
st.set_page_config(
    page_title="æš´èºçš„æ•™æˆè¯»è®ºæ–‡",
    layout="wide",
    initial_sidebar_state="expanded"
)

# åœ¨å¯¼å…¥ä¹‹åç«‹å³åˆå§‹åŒ–session state
if 'messages' not in st.session_state:
    st.session_state.messages = []
if 'show_log' not in st.session_state:
    st.session_state.show_log = False 
if 'edit_mode' not in st.session_state:
    st.session_state.edit_mode = False
# åœ¨ç°æœ‰session_stateåˆå§‹åŒ–åæ·»åŠ 
if 'ai_is_generating' not in st.session_state:
    st.session_state.ai_is_generating = False
if 'ai_current_request_id' not in st.session_state:
    st.session_state.ai_current_request_id = None
if 'ai_accumulated_response' not in st.session_state:
    st.session_state.ai_accumulated_response = ""
if 'selected_paper' not in st.session_state:
    st.session_state.selected_paper = None    
if 'selected_file' not in st.session_state:
    st.session_state.selected_file = 'article_zh'    # è®¾ç½®é»˜è®¤å€¼ä¸ºä¸­æ–‡æ–‡æ¡£
if 'ai_chat' not in st.session_state:
    st.session_state.ai_chat = AIProfessorChat()

# åˆå§‹åŒ–æ ¸å¿ƒæ¨¡å—
BASEDIR = os.path.dirname(os.path.abspath(__file__))

# æ•´ä¸ªåº”ç”¨ç”Ÿå‘½å‘¨æœŸå†…ä¿æŒå•ä¾‹
@st.cache_resource
def init_data_manager():
    data_manager = DataManager(BASEDIR)
    data_manager.load_papers_index()
    data_manager.scan_for_unprocessed_files()
    return data_manager

# æ›¿æ¢åŸæœ‰çš„åˆå§‹åŒ–
data_manager = init_data_manager()


# ä¿®æ”¹get_ai_responseä¸­çš„è°ƒç”¨
def get_ai_response(query, paper_id=None):
    try:
        print("âœ… [DEBUG] è¿›å…¥AIå“åº”æµç¨‹")  # æ§åˆ¶å°è¾“å‡º
        st.write("âœ… è¿›å…¥AIå“åº”æµç¨‹")
        print(f"ğŸ“¡ [DEBUG] è¯·æ±‚å‚æ•°: query='{query}', paper_id={paper_id}")  # å‚æ•°å¸¦å¼•å·é¿å…ç©ºæ ¼é—®é¢˜
        st.write(f"è¯·æ±‚å‚æ•°: query={query}, paper_id={paper_id}")
        
        if st.session_state.ai_is_generating:
            print("âš ï¸ [DEBUG] æ£€æµ‹åˆ°å·²æœ‰è¿›è¡Œä¸­çš„è¯·æ±‚ï¼Œè§¦å‘å–æ¶ˆ")
            st.warning("âš ï¸ æ£€æµ‹åˆ°å·²æœ‰ç”Ÿæˆä¸­çš„è¯·æ±‚ï¼Œæ­£åœ¨å–æ¶ˆ...")
            cancel_ai_response()
            
        # ç”Ÿæˆè¯·æ±‚ID
        st.session_state.ai_current_request_id = str(uuid.uuid4())
        st.session_state.ai_is_generating = True
        print(f"ğŸš€ [DEBUG] åˆ›å»ºæ–°è¯·æ±‚ID: {st.session_state.ai_current_request_id}")
        st.write(f"ğŸš€ åˆ›å»ºæ–°è¯·æ±‚ID: {st.session_state.ai_current_request_id}")
        
        # è·å–AIå“åº”
        print("ğŸ”„ [DEBUG] æ­£åœ¨è°ƒç”¨process_query_stream...")
        st.write("ğŸ”„ æ­£åœ¨è·å–AIå“åº”æµ...")
        response = st.session_state.ai_chat.process_query_stream(query, paper_id)
        
        # æ”¶é›†å®Œæ•´å“åº”
        full_response = ""
        for response_tuple in response:  # ä¿®æ”¹å˜é‡åä¸ºresponse_tuple
            sentence, emotion, scroll_info = response_tuple  # è§£åŒ…å…ƒç»„
            print(f"ğŸ“¥ [DEBUG] æ”¶åˆ°æµç‰‡æ®µ: {sentence}")  # åªè®°å½•æ–‡æœ¬å†…å®¹
            st.write(f"ğŸ“¥ æ”¶åˆ°å“åº”ç‰‡æ®µ: {sentence}")
            full_response += sentence
            yield sentence  # ä¿æŒåªè¿”å›æ–‡æœ¬å†…å®¹
            
        if not full_response:
            print("âŒ [ERROR] AIå“åº”ä¸ºç©ºï¼")
            st.error("âŒ AIå“åº”ä¸ºç©ºï¼Œè¯·æ£€æŸ¥AIæ¨¡å‹é…ç½®")
            
        # ä¿å­˜åˆ°å¯¹è¯å†å²
        st.session_state.ai_accumulated_response = full_response
        print("ğŸ’¾ [DEBUG] å“åº”ä¿å­˜å®Œæˆ")
        st.write("ğŸ’¾ å“åº”ä¿å­˜å®Œæˆ")
        
    except Exception as e:
        print(f"âŒ [CRITICAL] å¼‚å¸¸å‘ç”Ÿ: {str(e)}")
        st.error(f"âŒ AIå“åº”ç”Ÿæˆå¤±è´¥: {str(e)}")
        import traceback
        traceback.print_exc()  # æ§åˆ¶å°è¾“å‡ºå®Œæ•´å †æ ˆ
        st.write(f"ğŸ” å®Œæ•´é”™è¯¯è¿½è¸ª:\n{traceback.format_exc()}")
    finally:
        st.session_state.ai_is_generating = False
        print("ğŸ›‘ [DEBUG] æ¸…ç†ç”ŸæˆçŠ¶æ€")
        st.write("ğŸ›‘ æ¸…ç†ç”ŸæˆçŠ¶æ€")

def cancel_ai_response():
    if st.session_state.ai_is_generating:
        # é‡ç½®çŠ¶æ€
        st.session_state.ai_is_generating = False
        st.session_state.ai_current_request_id = None

def change_seleted_paper():
    paper_id = st.session_state.selected_paper
    if paper_id:
        print(f"ğŸ“š åˆ‡æ¢åˆ°è®ºæ–‡: {paper_id}")
        paper_data = data_manager.load_rag_tree(paper_id)
        if paper_data:
            print("ğŸ“š åŠ è½½RAGæ ‘æˆåŠŸ")
            st.session_state.ai_chat.set_paper_context(paper_id, paper_data)


# st.session_state.selected_paper = data_manager.papers_index[0]['id'] if data_manager.papers_index else None
# change_seleted_paper()



# åœ¨ç°æœ‰å‡½æ•°åæ·»åŠ æ–‡ä»¶ä¸Šä¼ å›è°ƒå‡½æ•°
def handle_file_upload():
    if "uploaded_file" in st.session_state:
        uploaded_file = st.session_state.uploaded_file
        file_id = uploaded_file.name.strip('.pdf').replace(" ", "_")[:50]

        if file_id in [p['id'] for p in data_manager.papers_index]:
            st.error("è¯¥è®ºæ–‡å·²å­˜åœ¨ï¼Œè¯·é€‰æ‹©å…¶ä»–æ–‡ä»¶")
            del st.session_state.uploaded_file
            return

        # ç¡®ä¿è·¯å¾„å¤„ç†æ­£ç¡®
        save_path = os.path.abspath(os.path.join("static", "data", file_id+".pdf"))
        with open(save_path, "wb") as f:
            f.write(uploaded_file.getbuffer())
        data_manager.upload_file(save_path)
        data_manager.is_paused = False
        data_manager.process_next_in_queue()
        # æ¸…é™¤ä¸Šä¼ çŠ¶æ€é˜²æ­¢é‡å¤è§¦å‘
        del st.session_state.uploaded_file

# ä¾§è¾¹æ  - è®ºæ–‡åˆ—è¡¨
with st.sidebar:
    with st.expander("ğŸ“š è®ºæ–‡åˆ—è¡¨", expanded=True):
        # è®ºæ–‡é€‰æ‹©
        selected_paper = st.selectbox(
            "é€‰æ‹©è®ºæ–‡",
            options=[p['id'] for p in data_manager.papers_index],
            format_func=lambda x: next(p['translated_title'] for p in data_manager.papers_index if p['id'] == x),
            key='selected_paper',
            on_change=change_seleted_paper,
            placeholder="è¯·é€‰æ‹©è®ºæ–‡",
        )

        if selected_paper:
            selected_file = st.selectbox(
                "é€‰æ‹©æ–‡ä»¶",
                options=['metadata', 'article_en', 'article_zh', 'rag_md', 'rag_tree'],
                format_func=lambda x: {
                    'metadata': 'å…ƒæ•°æ®',
                    'article_en': 'è‹±æ–‡æ–‡æ¡£',
                    'article_zh': 'ä¸­æ–‡æ–‡æ¡£',
                    'rag_md': 'RAGæ–‡æ¡£',
                    'rag_tree': 'RAGæ ‘'
                }[x],
                key='selected_file',
                placeholder="ä¸­æ–‡æ–‡æ¡£",
                index=2  # è®¾ç½®é»˜è®¤é€‰ä¸­'article_zh'ï¼ˆç¬¬3ä¸ªé€‰é¡¹ï¼‰
            )

            # æ–°å¢ï¼šæ˜¾ç¤º/éšè—MarkdownåŸæ–‡æŒ‰é’®ï¼ˆæ”¾åœ¨ä¾§è¾¹æ ï¼‰
            show_source_file_types = ['article_en', 'article_zh', 'rag_md']
            if selected_file in show_source_file_types:
                if 'show_markdown_source' not in st.session_state:
                    st.session_state['show_markdown_source'] = False
                btn_label = "æ˜¾ç¤ºMarkdownæºç " if not st.session_state['show_markdown_source'] else "æ¸²æŸ“Markdownè§†å›¾"
                if st.button(btn_label, key="toggle_md_source_btn_sidebar"):
                    st.session_state['show_markdown_source'] = not st.session_state['show_markdown_source']
                    st.rerun()  # æ·»åŠ rerun()æ¥è§£å†³æŒ‰é’®ç‚¹å‡»ä¸¤æ¬¡çš„é—®é¢˜

        col1, col2, col3 = st.columns([1,1,1])
        with col1:
            if st.button("ğŸ“ ç¼–è¾‘æ–‡ä»¶", key="edit_paper_btn"):
                st.session_state.edit_mode = True
        with col2:
            # åˆ é™¤è®ºæ–‡å¯¹åº”æ–‡ä»¶å¤¹
            if st.button("ğŸ—‘ï¸ åˆ é™¤è®ºæ–‡", key="delete_paper_btn"):
                paper_path = os.path.join(BASEDIR, 'output', st.session_state['selected_paper'])
                if os.path.exists(paper_path):
                    shutil.rmtree(paper_path)
                    st.rerun()
                else:
                    st.error("è®ºæ–‡æ–‡ä»¶å¤¹ä¸å­˜åœ¨")
        with col3:
            if st.button("ğŸ”„ åˆ·æ–°åˆ—è¡¨", key="refresh_db"):
                data_manager.deduplicate_paper_index()
    
    
    # ä¿®æ”¹æ–‡ä»¶ä¸Šä¼ ç»„ä»¶
    with st.expander("ğŸš€ å¤„ç†é˜Ÿåˆ—", expanded=True):
        uploaded_file = st.file_uploader(
            "ä¸Šä¼ è®ºæ–‡", 
            type=["pdf"],
            key="uploaded_file",
            on_change=handle_file_upload
        )
            
        # ä¿®æ”¹åçš„æ§åˆ¶æŒ‰é’®è¡Œ
        col1, col2, col3 = st.columns([1,1,1])
        with col1:
            # åˆ‡æ¢å¼æŒ‰é’®
            if data_manager.is_paused:
                if st.button("â–¶ï¸ ç»§ç»­å¤„ç†", key="resume_btn"):
                    data_manager.resume_processing()
                    data_manager.is_paused = False
            else:
                if st.button("â¸ï¸ æš‚åœå¤„ç†", key="pause_btn"):
                    data_manager.pause_processing()
                    data_manager.is_paused = True
        with col2:
            if st.button("ğŸ”„ æ›´æ–°è¿›åº¦", key="scan"):
                data_manager.scan_for_unprocessed_files()
        with col2:
            st.session_state['show_log'] = st.toggle("æ˜¾ç¤ºæ—¥å¿—", value=False)
        
        st.write(f"å½“å‰å¤„ç†é˜Ÿåˆ—ï¼ˆå…±{len(data_manager.processing_queue)}é¡¹ï¼‰ï¼Œæ˜¯å¦æš‚åœï¼š{data_manager.is_paused}ï¼Œæ­£åœ¨å¤„ç†ï¼š{data_manager.is_processing}")
        if data_manager.processing_queue:
            for item in data_manager.processing_queue:
                status_icon = {"pending": "â³", "processing": "ğŸ”„", "completed": "âœ…", "failed": "âŒ", "incomplete": "ğŸ”§"}[item['status']]
                st.write(f"{status_icon} ({item['status']}) {item['id']}")
            
            current_item = data_manager.processing_queue[0] if data_manager.processing_queue else None
            if current_item:
                progress_data = data_manager.processing_progress
                st.caption("å¤„ç†è¿›åº¦")
                st.write(f"{progress_data['stage_name']}\tprogress: {progress_data['progress']}% ({progress_data['index']}/{progress_data['total']})") 
                st.progress(progress_data['progress']/100)

            
    with st.expander("ğŸ’¬ AIå¯¹è¯", expanded=True):
        # èŠå¤©æ¶ˆæ¯æ˜¾ç¤º
        for msg in st.session_state.get("messages", []):
            with st.chat_message(msg["role"]):
                st.markdown(msg["content"])
        
        # ç”¨æˆ·è¾“å…¥
        # ä¿®æ”¹åŸæœ‰çš„èŠå¤©è¾“å…¥å¤„ç†éƒ¨åˆ†
        if prompt := st.chat_input("è¾“å…¥æ‚¨çš„é—®é¢˜..."):
            with st.spinner("æ•™æˆæ­£åœ¨æ€è€ƒ..."):
                # æ·»åŠ ç”¨æˆ·æ¶ˆæ¯
                st.session_state.messages.append({"role": "user", "content": prompt})
                
                # æµå¼è·å–AIå“åº”
                response_container = st.empty()
                full_response = ""
                for chunk in get_ai_response(prompt, selected_paper):
                    full_response += chunk
                    response_container.markdown(full_response + "â–Œ")
                
                # æ·»åŠ æœ€ç»ˆå“åº”
                st.session_state.messages.append({"role": "assistant", "content": full_response})
                st.rerun()

# ä¸»ç•Œé¢å¸ƒå±€
main_col = st.columns([10])[0]

# ä¿®æ”¹åŸæœ‰çš„æ¸²æŸ“éƒ¨åˆ†
with main_col:
    if st.session_state.show_log:
        log_container = st.empty()
        last_position = 0  # è¿½è¸ªæ–‡ä»¶è¯»å–ä½ç½®
        try:
            # åˆå§‹åŒ–æ—¶è·å–æœ€å20è¡Œ
            with open('stream.log', 'r') as f:
                lines = f.readlines()[-20:]
                log_content = "".join(lines)
                last_position = f.tell()
                log_container.markdown(log_content)  # æ”¹ç”¨textç»„ä»¶
            
            # æŒç»­ç›‘æ§æ›´æ–°
            import time
            while st.session_state.show_log:
                with open('stream.log', 'r') as f:
                    f.seek(last_position)
                    new_lines = f.readlines()
                    if new_lines:
                        log_content += "".join(new_lines)
                        # ä¿æŒæœ€å¤šä¿ç•™100è¡Œ
                        MAX_LINES = 100
                        if len(log_content.split('\n')) > MAX_LINES:
                            log_content = '\n'.join(log_content.split('\n')[-MAX_LINES:])
                        log_container.markdown(log_content)
                        last_position = f.tell()
                time.sleep(1)  # é™ä½æ£€æŸ¥é¢‘ç‡
        except FileNotFoundError:
            st.error("æ—¥å¿—æ–‡ä»¶stream.logä¸å­˜åœ¨")
    elif selected_paper:
        paper = data_manager.load_paper_content(selected_paper)
        content = paper[selected_file] if selected_file in paper else paper['article_zh']

        # æ·»åŠ ç¼–è¾‘æ¨¡å¼åˆ¤æ–­
        if st.session_state.edit_mode:
            # ç¼–è¾‘æ¨¡å¼æ˜¾ç¤ºæ–‡æœ¬ç¼–è¾‘æ¡†
            if selected_file in ['metadata', 'rag_tree']:
                content = json.dumps(content, indent=4, ensure_ascii=False)
            edited_content = st.text_area(
                "ç¼–è¾‘å†…å®¹",
                value=content,
                height=600,
                key="edit_content"
            )
            if st.button("ä¿å­˜ä¿®æ”¹"):
                # è¿™é‡Œå¯ä»¥æ·»åŠ ä¿å­˜é€»è¾‘
                data_manager.save_file(selected_paper, selected_file, edited_content)
                st.session_state.edit_mode = False
                st.success("ä¿®æ”¹å·²ä¿å­˜")

        else:
            # åŸæœ‰å†…å®¹æ¸²æŸ“é€»è¾‘
            show_source_file_types = ['article_en', 'article_zh', 'rag_md']
            if selected_file in show_source_file_types and st.session_state.get('show_markdown_source', False):
                # ä¿®æ”¹æ˜¾ç¤ºæ–¹å¼ï¼Œæ·»åŠ heightå‚æ•°ä½¿å…¶å æ»¡å¯ç”¨ç©ºé—´
                st.code(content, language="markdown", line_numbers=True, wrap_lines=True)
            elif selected_file in ['metadata', 'rag_tree']:
                st.json(content, expanded=True)
            else:
                # Generate TOC and add anchors to content
                toc = []
                content_with_anchors = content  # Initialize content with anchors

                # Extract headings and generate TOC
                def replace_heading(match):
                    level = len(match.group(1))  # Number of '#' determines the level
                    title = match.group(2).strip()  # Remove leading/trailing spaces
                    # Convert Chinese characters to pinyin
                    title_ascii = ''.join(lazy_pinyin(title))
                    anchor = urllib.parse.quote(title_ascii.replace(' ', '-').lower(), safe='')
                    toc.append((level, title, anchor))  # Add to TOC
                    return f'<h{level} id="{anchor}" data-custom-id="{anchor}">{title}</h{level}>'  # Add anchor to heading

                # Add anchors to content
                content_with_anchors = re.sub(r'(?m)^(#+)\s+(.*)', replace_heading, content)
                toc_markdown = []
                for level, title, anchor in toc:
                    indent = " " * (level - 1) * 4  # Indent based on heading level
                    toc_markdown.append(f"{indent}- [{title}](#{anchor})")
                toc_markdown = "\n".join(toc_markdown)
                print("ğŸ“‘ ç”Ÿæˆç›®å½•å®Œæˆ", toc)

                with st.expander("ğŸ“‘ ç›®å½•", expanded=True):
                    st.markdown(toc_markdown, unsafe_allow_html=True)

                image_prefix = os.path.join('app', 'static', 'output', selected_paper)
                # å¦‚æœè·¯å¾„ä¸­å‡ºç°äº†ç©ºæ ¼ï¼Œæ›¿æ¢ä¸º%20
                image_prefix = image_prefix.replace(" ", "%20")
                # Replace image paths in content
                content_with_anchors = re.sub(r'!\[(.*?)\]\((.*?)\)', lambda m: f'![{m.group(1)}]({image_prefix}/{m.group(2)})', content_with_anchors)

                print("ğŸ“· æ›¿æ¢å›¾ç‰‡è·¯å¾„å®Œæˆ", content_with_anchors)
                # Render the combined markdown
                st.markdown(content_with_anchors, unsafe_allow_html=True)

                # æ²¡æœ‰è¾“å‡ºæ˜¯å› ä¸º Streamlit çš„ st.components.v1.html æ³¨å…¥çš„ JavaScript ä»£ç è¿è¡Œåœ¨ä¸€ä¸ª iframe ä¸­
                # JavaScript ä»£ç æ— æ³•ç›´æ¥è®¿é—®ä¸»é¡µé¢çš„ DOMï¼Œå› æ­¤æ— æ³•ä¿®æ”¹ä¸»é¡µé¢çš„æ ‡é¢˜ idã€‚
                st.components.v1.html("""
                <script>
                    function checkHeaders() {
                        console.log('Checking and updating headers...');
                        parent.document.querySelectorAll("h1, h2, h3, h4, h5, h6").forEach((el) => {
                            const customId = el.getAttribute('data-custom-id');
                            if (customId && el.id !== customId) {
                                el.id = customId;  // æ›¿æ¢ Streamlit è‡ªåŠ¨ç”Ÿæˆçš„ ID
                                console.log(`Updated ID: ${customId}`);
                            }
                        });
                    }

                    // æ¯éš”2ç§’æ£€æŸ¥ä¸€æ¬¡
                    // setInterval(() => checkHeaders(), 2000);
                    setTimeout(() => checkHeaders(), 1000);  // åˆå§‹è°ƒç”¨
                    setTimeout(() => checkHeaders(), 2000);  // åˆå§‹è°ƒç”¨
                </script>
                """, height=0)
    
    else:
        st.markdown("""
# å“¼ï¼åˆæ¥ä¸€ä¸ªä¸è¯»è®ºæ–‡çš„å­¦ç”Ÿæ˜¯å§ï¼Ÿ

å¾ˆå¥½ï¼Œè‡³å°‘ä½ çŸ¥é“æ‰“å¼€è¿™ä¸ªè½¯ä»¶ã€‚æˆ‘æ˜¯ä½ çš„è®ºæ–‡æŒ‡å¯¼æ•™æˆï¼Œ**ä¸è¦æœŸæœ›æˆ‘å¯¹ä½ æ‰‹ä¸‹ç•™æƒ…**ã€‚

## å¬å¥½äº†ï¼Œè¿™æ˜¯ä½ èƒ½åšçš„äº‹ï¼š

- **é€‰è®ºæ–‡**ï¼šå·¦è¾¹é‚£ä¸€å †ï¼ŒæŒ‘ä¸€ç¯‡ä½ èƒ½çœ‹æ‡‚çš„ï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰
- **æ¢è¯­è¨€**ï¼šä¸­è‹±æ–‡çœ‹ä¸æ‡‚ï¼ŸæŒ‰ä¸Šé¢é‚£ä¸ªæŒ‰é’®åˆ‡æ¢ï¼Œåˆ«æŒ‡æœ›æ¢äº†è¯­è¨€å°±èƒ½ç†è§£å†…å®¹
- **é—®é—®é¢˜**ï¼šæœ‰ä¸æ‡‚çš„å°±å³è¾¹æé—®ï¼Œæˆ‘ä¼šå›ç­”ï¼Œè™½ç„¶ä½ çš„é—®é¢˜å¯èƒ½å¾ˆè ¢
- **çœ‹æ‘˜è¦**ï¼šæ‡’å¾—è¯»å…¨æ–‡ï¼Ÿæˆ‘ç»™ä½ æ€»ç»“é‡ç‚¹ï¼Œçœå¾—ä½ åˆ°å¤„æŠ“ç

## å¼€å§‹ç”¨å§ï¼Œåˆ«ç£¨è¹­ï¼

ä»å·¦è¾¹éšä¾¿é€‰ä¸€ç¯‡ï¼Œç„¶åå¼€å§‹è¯»ã€‚æœ‰ä¸æ˜ç™½çš„å°±é—®æˆ‘ï¼Œ**åˆ«æ†‹ç€è£…æ‡‚**ï¼

è®°ä½ï¼š_çœŸæ­£çš„å­¦æœ¯æ˜¯åˆ€å°–èµ·èˆï¼Œè€Œä¸æ˜¯åƒä½ å¹³æ—¶é‚£æ ·æµ…å°è¾„æ­¢ï¼_

...ä¸è¿‡åˆ«æ‹…å¿ƒï¼Œæˆ‘ä¼šä¸€ç›´åœ¨è¿™é™ªä½ è¯»å®Œçš„ã€‚
""")


with open("static/css/style.css", "r", encoding="utf-8") as f:
    st.markdown(f"<style>{f.read()}</style>", unsafe_allow_html=True)

